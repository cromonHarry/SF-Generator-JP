# 🚀 Near Future SF Generator

This is a **Streamlit-based application** that helps users generate a **3-steps development timeline** and a **short sci-fi story** based on a real-world product and user experience, guided by the **S-Curve model** and **Archaeological Prototyping (AP) model**.

## 🔍 Features

- Upload a **product image**
- Input:
  - Product name
  - User experience description
  - Potential avant-garde issue
- Automatically generate:
  - **Technology evolution timeline** 3 steps based on S-Curve model
  - **Sociocultural background changes** based on AP model
  - **Original science fiction story** (with AI-generated cover)
- Downloadable results:
  - Timeline (`description_history.json`)
  - AP background (`background_history.json`)
  - Sci-fi story (`story.txt`)
  - Story cover image (`cover.png`)


## 📦 Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/near-future-sf-generator.git
   cd near-future-sf-generator
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Add your OpenAI API key as an environment variable:
   ```bash
   export OPENAI_API_KEY=your-api-key
   ```

4. Run the app:
   ```bash
   streamlit run app.py
   ```

## 🧠 Models Used

- **OpenAI GPT-4o**
- **OPENAI GPT-Image-1**


## 🧪 Example Use Case

1. **Product**: Smart Glasses  
2. **Experience**: Real-time translation, AR navigation  
3. **Issue**: Over-dependence, privacy risks  
➡️ Generates an original story imagining future impacts.


## 📝 Evaluation

To test the quality of AP-based generated story, we also asked LLM to directly generate a short story only based on user input, and we designed 2 methods to evaluate. The samples are stored in `samples` folder.

1. **Benchmark Evaluation**:
   You can check it by runing:
   ```
   pip install nltk textstat
   python benchmark_eval.py
   ```

2. **LLM Evaluation**:
   We evaluate the results by using grok-3 and qwen3-4b.(Since the samples are generated by GPT-4o, we do not use GPT to do evaluation). So you should use your own grok api key and download LM Studio for qwen3-4b.
   You can check it by runing:
   ```
   python llm_eval.py
   ```

## 📄 Acknowledgments

- [Streamlit](https://streamlit.io/)
- [OpenAI](https://openai.com/)
- [S-Curve Model](https://en.wikipedia.org/wiki/S-curve)

## 📜 License

MIT License
